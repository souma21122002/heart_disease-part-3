{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrvhTWVWgJ_d"
   },
   "source": [
    "Important Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "irCOqNjsfnv3"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _c_internal_utils: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\__init__.py:159\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sanitize_sequence\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\cbook.py:32\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VisibleDeprecationWarning\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _c_internal_utils\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_running_interactive_framework\u001b[39m():\n\u001b[0;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m    Return the interactive framework whose event loop is currently running, if\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    any, or \"headless\" if no event loop can be started, or None.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m        \"macosx\", \"headless\", ``None``.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _c_internal_utils: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# We're not going to use sklearn's LogisticRegression\n",
    "# from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pExinTrvhOV7"
   },
   "source": [
    "Date collection and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sxyi2zBxhM-s"
   },
   "outputs": [],
   "source": [
    "heart_data=pd.read_csv('Cardiovascular_Disease_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "TqBaWmEkhdaU",
    "outputId": "29dde0f1-22d3-4f90-e745-7cd5ed61cd52"
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "YdtfYMvjhjAI",
    "outputId": "117455ed-8090-4912-9ddc-bed3e8a4e82e"
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HIMKQGZghspd",
    "outputId": "314d8097-56a7-4899-dea5-abce0fb57972"
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cwj37CkghzTS",
    "outputId": "95ef4764-e359-47e3-acb6-5a868a1de593"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "heart_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "u-ZVFKGZh81D",
    "outputId": "1ef2cfc4-8b73-48bd-c8eb-dad6cc0c9ef9"
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "jW90ew_8iFQi",
    "outputId": "9a2a6a47-486e-4f21-cef5-d77c461f54ff"
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "NynD7-XliQ9D",
    "outputId": "ebba3970-8300-4dce-f115-7c9882292ff2"
   },
   "outputs": [
    {
     "data": {},
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mskJv1c6jqE9"
   },
   "source": [
    "1--> defective heart\n",
    "0-->healthy heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "Pc5gZH5Bjb4_"
   },
   "outputs": [],
   "source": [
    "X=heart_data.drop(columns='target',axis=1)\n",
    "Y=heart_data['target']\n",
    "X=X.drop(columns='patientid',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t5GEMLg3kISQ",
    "outputId": "2db3801f-063c-4f7b-b440-d694f4a3833b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AuIRBDxIkSfo",
    "outputId": "8bceb12e-abcc-4b34-ca27-97a5a5bb8289"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHTES25Jkdnp"
   },
   "source": [
    "Splitting the data into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "MKqVzc4CkXjh"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,stratify=Y,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FAl7XkGPmjKd",
    "outputId": "b930cd8b-190c-4d92-a880-1b6c6dbe7bd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print(X.shape,X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom LogisticRegression Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, max_iter=1000, lambda_=0.01, verbose=False, scaler=None):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.lambda_ = lambda_  # Regularization parameter\n",
    "        self.verbose = verbose\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.scaler = scaler\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        # Clip z to avoid overflow\n",
    "        z = np.clip(z, -500, 500)\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def initialize_weights(self, n_features):\n",
    "        # Initialize weights with small random values\n",
    "        self.weights = np.random.randn(n_features) * 0.01\n",
    "        self.bias = 0\n",
    "    \n",
    "    def compute_cost(self, X, y, predicted):\n",
    "        # Compute the cost function with L2 regularization\n",
    "        m = X.shape[0]\n",
    "        # Avoid log(0) by clipping predicted values\n",
    "        predicted = np.clip(predicted, 1e-10, 1 - 1e-10)\n",
    "        cost = (-1/m) * (np.dot(y, np.log(predicted)) + np.dot((1-y), np.log(1-predicted)))\n",
    "        # Add regularization term (exclude bias from regularization)\n",
    "        reg_cost = (self.lambda_ / (2*m)) * np.sum(np.square(self.weights))\n",
    "        return cost + reg_cost\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Convert to numpy arrays if not already\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        \n",
    "        # Get number of samples and features\n",
    "        m, n_features = X.shape\n",
    "        \n",
    "        # Initialize weights and bias\n",
    "        self.initialize_weights(n_features)\n",
    "        \n",
    "        # Gradient descent optimization\n",
    "        for i in range(self.max_iter):\n",
    "            # Forward pass: compute predictions\n",
    "            z = np.dot(X, self.weights) + self.bias\n",
    "            predictions = self.sigmoid(z)\n",
    "            \n",
    "            # Compute gradients\n",
    "            dw = (1/m) * np.dot(X.T, (predictions - y)) + (self.lambda_ / m) * self.weights\n",
    "            db = (1/m) * np.sum(predictions - y)\n",
    "            \n",
    "            # Update parameters\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "            \n",
    "            # Print cost every 100 iterations if verbose\n",
    "            if self.verbose and i % 100 == 0:\n",
    "                cost = self.compute_cost(X, y, predictions)\n",
    "                print(f\"Iteration {i}, Cost: {cost}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # Convert to numpy array if not already\n",
    "        X = np.asarray(X)\n",
    "        \n",
    "        # Apply feature scaling if available\n",
    "        if self.scaler is not None:\n",
    "            X = self.scaler.transform(X)\n",
    "        \n",
    "        # Compute probability estimates\n",
    "        z = np.dot(X, self.weights) + self.bias\n",
    "        probabilities = self.sigmoid(z)\n",
    "        \n",
    "        # Return probabilities for both classes (similar to sklearn API)\n",
    "        return np.column_stack([1-probabilities, probabilities])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Predict class labels (0 or 1)\n",
    "        probabilities = self.predict_proba(X)[:, 1]  # Probability of class 1\n",
    "        return (probabilities >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZGTG9ACm2TK"
   },
   "source": [
    "## Create and Apply Feature Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a scaler and fit it to the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "iNkNnMQnm9cF",
    "outputId": "8cdbfe23-cd0d-4a0c-dc84-b8aa8fecb7a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {},
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and train our custom model with feature scaling\n",
    "model = LogisticRegression(learning_rate=0.01, max_iter=1000, lambda_=0.01, verbose=True, scaler=scaler)\n",
    "model.fit(X_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gXa2a5UJnHkV"
   },
   "outputs": [],
   "source": [
    "X_train_prediction = model.predict(X_train_scaled)\n",
    "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tuj1ncbqnscv",
    "outputId": "3bf5fa6f-efac-44e4-e82c-098de40b32fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print('Accuracy on training data:', training_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OZPFQrPpn5SA"
   },
   "outputs": [],
   "source": [
    "X_test_prediction = model.predict(X_test_scaled)\n",
    "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rQlQI86poM6B",
    "outputId": "601a3773-da21-49fc-858d-bf4ee4d81801"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "print('Accuracy on test data:', test_data_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czdopGaHodIt"
   },
   "source": [
    "Building Predicting System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7VB6BZhWoRAq",
    "outputId": "8b9c8eaf-cabf-4788-b7f3-2addedb3415d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "input_data = (58, 1, 2, 140, 300, 0, 0, 140, 0, 1.5, 2, 0)\n",
    "input_data_as_numpy_array = np.asarray(input_data)\n",
    "input_data_reshaped = input_data_as_numpy_array.reshape(1, -1)\n",
    "\n",
    "# Scale the input data\n",
    "input_data_scaled = scaler.transform(input_data_reshaped)\n",
    "\n",
    "# Make prediction\n",
    "prediction = model.predict(input_data_scaled)\n",
    "print(prediction)\n",
    "\n",
    "if prediction[0] == 0:\n",
    "    print('The person does not have a heart disease')\n",
    "else:\n",
    "    print('The person has heart disease')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the custom model to a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model to a pickle file\n",
    "pickle.dump(model, open('heart_disease_model4.pkl', 'wb'))\n",
    "print('Model saved successfully as heart_disease_model4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18VgkA7To_wA"
   },
   "outputs": [],
   "source": [
    "# Test loading the model back in to make sure it works\n",
    "loaded_model = pickle.load(open('heart_disease_model4.pkl', 'rb'))\n",
    "test_prediction = loaded_model.predict(input_data_scaled)\n",
    "print(f\"Test prediction from loaded model: {test_prediction}\")\n",
    "\n",
    "if test_prediction[0] == 0:\n",
    "    print('The person does not have a heart disease')\n",
    "else:\n",
    "    print('The person has heart disease')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
